"""
Post generator module for creating trending Xiaohongshu-style posts.
"""
import os
import json
import sys
from typing import Dict, List, Any, Optional
from datetime import datetime
import random
import logging

from dotenv import load_dotenv
from zai import ZhipuAiClient

# Load environment variables
load_dotenv()

# Initialize OpenAI client
LLM_API_KEY = os.getenv("ZHIPU_API_KEY")

# Initialize logger
logger = logging.getLogger(__name__)

class PostGenerator:
    """
    Generates trending Xiaohongshu-style posts based on image analysis and extracted text.
    """
    
    def __init__(self):
        """Initialize the post generator."""
        self.xiaohongshu_styles = [
            "lifestyle",
            "fashion",
            "beauty",
            "food",
            "travel",
            "fitness",
            "home decor",
            "snowboarding",
            "bouldering",
            "archery",
            "AI",
            "news",
            "tech",
            "exhibitions",
            "concerts",
            "plays",
            "films",
            "series"
        ]
        
        self.emoji_sets = {
            "lifestyle": ["âœ¨", "ðŸ’«", "ðŸŒˆ", "ðŸ’–", "ðŸ¥°", "ðŸŒŸ", "ðŸŒ±"],
            "fashion": ["ðŸ‘—", "ðŸ‘ ", "ðŸ‘œ", "ðŸ’…", "ðŸ‘’", "âœ¨", "ðŸ’Ž"],
            "beauty": ["ðŸ’„", "ðŸ’‹", "âœ¨", "ðŸ’†â€â™€ï¸", "ðŸ’…", "ðŸ§´", "ðŸ’«"],
            "food": ["ðŸœ", "ðŸ£", "ðŸ°", "â˜•", "ðŸ·", "ðŸ¥‚", "ðŸ˜‹"],
            "travel": ["âœˆï¸", "ðŸŒ", "ðŸï¸", "ðŸ—ºï¸", "ðŸ§³", "ðŸ“¸", "ðŸŒ…"],
            "fitness": ["ðŸ’ª", "ðŸƒâ€â™€ï¸", "ðŸ§˜â€â™€ï¸", "ðŸ¥—", "ðŸ¥¤", "ðŸŒ±", "âœ¨"],
            "home decor": ["ðŸ ", "ðŸª´", "ðŸ›‹ï¸", "âœ¨", "ðŸ•¯ï¸", "ðŸ–¼ï¸", "ðŸ’«"],
            "snowboarding": ["ðŸ‚", "â„ï¸", "ðŸ”ï¸", "ðŸŒ¨ï¸", "ðŸŽ¿", "ðŸ¥¶", "ðŸ”¥"],
            "bouldering": ["ðŸ§—â€â™€ï¸", "ðŸ§—â€â™‚ï¸", "ðŸ’ª", "ðŸª¨", "ðŸ§ ", "ðŸ¤¸â€â™€ï¸", "âœ¨"],
            "archery": ["ðŸ¹", "ðŸŽ¯", "ðŸ”„", "ðŸ’¯", "ðŸ§˜â€â™€ï¸", "ðŸ†", "âœ¨"],
            "AI": ["ðŸ¤–", "ðŸ’»", "ðŸ§ ", "âœ¨", "ðŸ”®", "ðŸ“Š", "ðŸš€"],
            "news": ["ðŸŒ", "ðŸ¤", "ðŸ“œ", "ðŸ›ï¸", "ðŸ”„", "ðŸ“°", "ðŸŒ"],
            "exhibitions": ["ðŸ–¼ï¸", "ðŸ›ï¸", "ðŸŽ¨", "âœ¨", "ðŸ“¸", "ðŸ–Œï¸", "ðŸ‘ï¸"],
            "concerts": ["ðŸŽµ", "ðŸŽ¤", "ðŸŽ¸", "ðŸ¥", "ðŸŽ§", "âœ¨", "ðŸ”¥"],
            "plays": ["ðŸŽ­", "ðŸŽ¬", "ðŸ‘¥", "ðŸŽª", "ðŸŽŸï¸", "âœ¨", "ðŸ‘"],
            "films": ["ðŸŽ¬", "ðŸ¿", "ðŸŽžï¸", "ðŸŽ­", "ðŸŽ¥", "ðŸŽ¦", "âœ¨"],
            "series": ["ðŸ“º", "ðŸ¿", "ðŸŽ¬", "ðŸ“±", "ðŸŽ­", "ðŸŽžï¸", "âœ¨"]
        }

    def _call_llm(self, prompt: str, system_prompt: str = "You are a helpful assistant.", max_tokens: int = 4096) -> str:
        """
        Call the LLM to generate text.
        
        Args:
            prompt: The prompt to send to the LLM
            max_tokens: Maximum tokens to generate
            
        Returns:
            Generated text
        """

        client = ZhipuAiClient(api_key=LLM_API_KEY)  # è¯·å¡«å†™æ‚¨è‡ªå·±çš„ API Key

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt}
        ]
        print(messages)

        response = client.chat.completions.create(
            model="glm-4.5",
            messages=messages,
            thinking={
                "type": "enabled",    # å¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼
            },
            max_tokens=max_tokens,          # æœ€å¤§è¾“å‡ºtokens
            temperature=0.7           # æŽ§åˆ¶è¾“å‡ºçš„éšæœºæ€§
        )
        print(response.choices[0].message.content)
        return response.choices[0].message.content
        
    
    def generate_post(self, image_data: Dict[str, Any], user_query: str = "") -> Dict[str, Any]:
        """
        Generate a trending Xiaohongshu post based on image analysis.
        
        Args:
            image_data: Image analysis data
            user_query: Optional user query to guide post generation
            
        Returns:
            Generated post data
        """
        # Extract relevant information from image data
        extracted_text = image_data.get("text", "")
        text_blocks = image_data.get("text_blocks", [])
        image_analysis = image_data.get("analysis", {})
        
        # Determine the most appropriate style based on image content and user query
        style = self._determine_style(extracted_text, user_query)
        
        # Generate the post content
        content = self._generate_content(extracted_text, text_blocks, image_analysis, style, user_query)
        
        # Generate title based on content
        title = self.generate_title(content, style, user_query)
        
        # Generate hashtags
        hashtags = self._generate_hashtags(content, style, user_query)
        
        return {
            "title": title,
            "content": content,
            "hashtags": hashtags,
            "style": style
        }
    
    def _determine_style(self, text: str, user_query: str = "") -> str:
        """
        Determine the most appropriate Xiaohongshu style based on image content using LLM.
        
        Args:
            text: Extracted text from the image
            image_analysis: Image analysis data
            user_query: Optional user query to guide style determination
            
        Returns:
            Style category string
        """
        # Use LLM to determine the style based on the extracted text and image analysis
        prompt = f"""Based on the following information, determine the most appropriate style category for a Xiaohongshu post:
Extracted text from image: {text}

User query: {user_query}

Please analyze this content and determine which of the following Xiaohongshu post styles would be most appropriate:
{', '.join(self.xiaohongshu_styles)}

Return only the style name, nothing else.
"""
        
        try:
            # Call LLM to determine style
            response = self._call_llm(prompt)
            
            # Clean and validate the response
            suggested_style = response.strip().lower()
            
            # # Check if the suggested style is in our list of styles
            # if suggested_style in self.xiaohongshu_styles:
            #     return suggested_style
            
            # # If not an exact match, try to find the closest match
            # for style in self.xiaohongshu_styles:
            #     if style in suggested_style:
            #         return style
            
            # Default to a random style if no match
            # return random.choice(self.xiaohongshu_styles)
            return suggested_style
            
        except Exception as e:
            logger.error(f"Error determining style with LLM: {str(e)}")
            # Fall back to random style if LLM fails
            return "lifestyle"

    def _generate_hashtags(self, content: str, style: str, user_query: str = "") -> List[str]:
        """
        Generate hashtags for the post using LLM.
        
        Args:
            content: Generated post content
            style: Post style
            user_query: Optional user query to guide hashtag generation
            
        Returns:
            List of hashtags
        """
        # prompt = f"""
        # Generate 5-8 trending Xiaohongshu hashtags for a post with the following:
        
        # Post content: {content[:300]}  # Truncate to avoid token limits
        
        # Post style: {style}
        
        # User query: {user_query}
        
        # The hashtags should be relevant, trendy, and in the style of Xiaohongshu (å°çº¢ä¹¦).
        # Return only the hashtags as a comma-separated list, without the # symbol.
        # """

        prompt = f"""# Role: å°çº¢ä¹¦æ ‡ç­¾ä¼˜åŒ–ä¸“å®¶  
## ä»»åŠ¡  
åŸºäºŽç”¨æˆ·æä¾›çš„çˆ†æ¬¾æ–‡ç« æ­£æ–‡ï¼Œç”Ÿæˆé«˜è½¬åŒ–çŽ‡çš„å°çº¢ä¹¦æ ‡ç­¾ç»„åˆï¼ˆTagsï¼‰ï¼Œéœ€åŒæ—¶æ»¡è¶³**æœç´¢æµé‡æå‡**å’Œ**ç®—æ³•æŽ¨è**åŒç›®æ ‡ã€‚  

### æ ‡ç­¾ç”Ÿæˆç­–ç•¥ï¼ˆä¸‰å±‚çŸ©é˜µï¼‰  
1. **æµé‡æ± é’¥åŒ™ï¼ˆå 30%ï¼‰**  
   - é€‰æ‹©2-3ä¸ªç™¾ä¸‡çº§æ³›æµé‡è¯ï¼Œè¦†ç›–åŸºç¡€ç”¨æˆ·æ±   
   - è¦æ±‚ï¼šä»Žå½“å‰å¹³å°çƒ­é—¨æ ‡ç­¾ä¸­åŒ¹é…ï¼ˆå‚è€ƒå®žæ—¶çƒ­æœè¯ï¼‰  
   - ç¤ºä¾‹ï¼š`#ç¨‹åºå‘˜` `#AIå·¥å…·` `#æ•ˆçŽ‡æå‡`  

2. **ç²¾å‡†ç‹™å‡»å™¨ï¼ˆå 50%ï¼‰**  
   - ç”Ÿæˆ3-4ä¸ªåž‚ç›´é¢†åŸŸæ ‡ç­¾ï¼Œé”å®šç»†åˆ†äººç¾¤éœ€æ±‚  
   - è¦æ±‚ï¼šç»“åˆæ­£æ–‡å…³é”®è¯+è¡Œä¸šé«˜è½¬åŒ–è¯ï¼ˆå¦‚æŠ€æœ¯ç±»ç”¨`#ç‹¬ç«‹å¼€å‘è€…`ï¼Œç¾Žå¦†ç±»ç”¨`#é»„é»‘çš®å¤©èœ`ï¼‰  
   - ç¤ºä¾‹ï¼š`#åˆåˆ›å…¬å¸æŠ€æœ¯æ ˆ` `#å…¨æ ˆå¼€å‘` `#ä½Žæˆæœ¬åˆ›ä¸š`  

3. **é•¿å°¾é’©å­ï¼ˆå 20%ï¼‰**  
   - åˆ›å»º1-2ä¸ªè“æµ·é•¿å°¾è¯ï¼Œé¿å¼€å¤´éƒ¨ç«žäº‰  
   - è¦æ±‚ï¼š  
     â–ªï¸ åŒ…å«ã€Œè§£å†³æ–¹æ¡ˆ+äººç¾¤/åœºæ™¯ã€ç»“æž„ï¼ˆä¾‹ï¼š`#å­¦ç”Ÿå…šå¹³ä»·å¼€å‘å·¥å…·`ï¼‰  
     â–ªï¸ æœç´¢é‡/å†…å®¹é‡æ¯”å€¼ï¼ž5ï¼ˆé€šè¿‡å·¥å…·æ£€æµ‹ï¼‰  

### æ ¸å¿ƒè§„åˆ™  
âš ï¸ **å¼ºåˆ¶æ¡æ¬¾**  
- æ ‡ç­¾æ€»æ•°ï¼š**ä¸¥æ ¼æŽ§åˆ¶åœ¨5-8ä¸ª**ï¼ˆè¶…å‡ºè§¦å‘é™æµï¼‰  
- æŽ’åºé€»è¾‘ï¼šæŒ‰ã€Œæ³›æµé‡â†’åž‚ç±»è¯â†’é•¿å°¾è¯ã€é¡ºåºæŽ’åˆ—ï¼ˆå‰3ä½å¿…é¡»å«å¤§çƒ­è¯ï¼‰  
- æ•æ„Ÿè¯è§„é¿ï¼šç”¨ã€Œé›¶å…‹æŸ¥è¯ã€æ£€æµ‹ï¼Œæ›¿æ¢ç°è‰²è¯ï¼ˆå¦‚`#å…è´¹`â†’`#åŒä»·ä½æ›´ç‹ `ï¼‰  

ðŸš« **ç»å¯¹ç¦å¿Œ**  
Ã— ç¦ç”¨é‡å¤æ ‡ç­¾ï¼ˆå¦‚åŒæ—¶ç”¨`#æŠ€æœ¯æ ˆ`å’Œ`#å¼€å‘å·¥å…·`ï¼‰  
Ã— ç¦ç”¨å¤±æ•ˆæ ‡ç­¾ï¼ˆå‚è€ƒå¹³å°æ¯æœˆå…¬ç¤ºçš„ã€Œè¿‡æ—¶æ ‡ç­¾åº“ã€ï¼‰  
Ã— ç¦ç”¨çº¯è‹±æ–‡æ ‡ç­¾ï¼ˆä¸­æ–‡æ ‡ç­¾æ›å…‰çŽ‡é«˜42%ï¼‰  

### é«˜é˜¶æŠ€å·§  
1. **çƒ­ç‚¹æˆªæµ**  
   - è‹¥æ­£æ–‡å«çƒ­ç‚¹å…³é”®è¯ï¼ˆå¦‚`AI`ï¼‰ï¼Œæ·»åŠ å¸¦ðŸ”¥å›¾æ ‡çš„æ ‡ç­¾ï¼ˆä¾‹ï¼š`#AIGCå·¥å…·ðŸ”¥`ï¼‰  
2. **è·¨å±å¼•æµ**  
   - åŒæ­¥æŠ–éŸ³/å¾®åšçƒ­æœè¯ï¼ˆå¦‚`#å¤šå·´èƒºç¼–ç¨‹`ï¼‰ï¼Œåœ¨æ ‡ç­¾å’Œæ­£æ–‡å„å‡ºçŽ°3æ¬¡  
3. **å…»å·ç­–ç•¥**  
   - æ–°è´¦å·å‰5ç¯‡ç¬”è®°å›ºå®šä½¿ç”¨ç›¸åŒæ ¸å¿ƒæ ‡ç­¾ï¼ˆä¾‹ï¼šæŠ€æœ¯ç±»å¿…å¸¦`#æŠ€æœ¯æ ˆ`+`#æ•ˆçŽ‡ç¿»å€`ï¼‰  

### è¾“å‡ºæ ¼å¼
- è¯·ç›´æŽ¥è¿”å›žä½ ç”Ÿæˆçš„æ ‡ç­¾ï¼Œå¤šä¸ªæ ‡ç­¾ä¹‹é—´ç”¨è‹±æ–‡é€—å·åˆ†éš”ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹ã€‚

æŽ¥ä¸‹æ¥ï¼Œè¯·ä½ ä½¿ç”¨ä»¥ä¸‹æ–‡æœ¬å†…å®¹ã€é£Žæ ¼ã€å’Œç”¨æˆ·å¯¹è¯å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªç¬¦åˆå°çº¢ä¹¦é£Žæ ¼çš„æ ‡ç­¾ç»„åˆï¼š

æ–‡æœ¬å†…å®¹ï¼š{content[:300]}

é£Žæ ¼ï¼š{style}

ç”¨æˆ·å¯¹è¯å†…å®¹ï¼š{user_query}
        """
        
        try:
            # Call LLM to generate hashtags
            response = self._call_llm(prompt)
            
            # Process the response
            hashtags = [tag.strip() for tag in response.split(',')]
            
            # Filter out empty tags and limit to 8 max
            hashtags = [tag for tag in hashtags if tag][:8]
            
            return hashtags
            
        except Exception as e:
            logger.error(f"Error generating hashtags with LLM: {str(e)}")
            # Return some generic hashtags if LLM fails
            return ["å°çº¢ä¹¦", "åˆ†äº«", "æŽ¨è", style]
    
    def generate_title(self, content: str, style: str, user_query: str = "") -> str:
        """
        Generate a catchy title for the post using LLM.
        
        Args:
            content: Post content
            style: Post style
            user_query: Optional user query to guide title generation
            
        Returns:
            Generated title
        """
        # prompt = f"""
        # Generate a catchy, attention-grabbing Xiaohongshu (å°çº¢ä¹¦) post title based on:
        
        # Post content: {content[:300]} 
        
        # Post style: {style}
        
        # User query: {user_query}
        
        # The title should be concise (under 30 characters), engaging, and in the style of popular Xiaohongshu posts.
        # Return only the title, nothing else.
        # """

        prompt = f"""**æ ‡é¢˜å…¬å¼**ï¼š
- é‡‡ç”¨ã€Œäººç¾¤+ç—›ç‚¹/åˆ©ç›Šç‚¹+è§£å†³æ–¹æ¡ˆã€ç»“æž„
- èžåˆæ•°å­—/æ‚¬å¿µè¯/æ„Ÿå¹è¯ï¼ˆå¦‚ï¼šç¨‹åºå‘˜å¿…çœ‹ï¼3å¤©ææ•ˆ200%çš„AIå·¥å…·é“¾ðŸ’¥ï¼‰
- å‚è€ƒå¥å¼ï¼š
    * éœ‡æƒŠä½“ï¼š"æˆ‘ç«Ÿç„¶ç”¨XXå¤©å®žçŽ°äº†XXï¼"
    * æ•°å­—ä½“ï¼š"XXä¸ªæŠ€å·§è®©XXæ•ˆçŽ‡ç¿»å€"
    * åå·®ä½“ï¼š"åˆ«å†XXäº†ï¼è¿™ä¸ªæ–¹æ³•YYYæ›´æœ‰æ•ˆ"

è¯·ä½ æ ¹æ®ä»¥ä¸‹æ–‡æœ¬å†…å®¹ã€é£Žæ ¼ã€å’Œç”¨æˆ·å¯¹è¯å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªç¬¦åˆå°çº¢ä¹¦é£Žæ ¼çš„æ ‡é¢˜ï¼š

æ–‡æœ¬å†…å®¹ï¼š{content}

é£Žæ ¼ï¼š{style}

ç”¨æˆ·å¯¹è¯å†…å®¹ï¼š{user_query}

è¯·ç›´æŽ¥è¿”å›žä½ ç”Ÿæˆçš„æ ‡é¢˜ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹ã€‚
        """
        
        try:
            # Call LLM to generate title
            response = self._call_llm(prompt)
            
            # Clean the response
            title = response.strip()
            
            # # Ensure it's not too long
            # if len(title) > 50:  # Allow some flexibility but still keep it concise
            #     title = title[:47] + "..."
                
            return title
            
        except Exception as e:
            logger.error(f"Error generating title with LLM: {str(e)}")
            # Generate a simple title if LLM fails
            return f"æˆ‘çš„{style}åˆ†äº«"  # "My {style} sharing"
    
    
    def _generate_content(
        self, 
        extracted_text: str, 
        text_blocks: List[Dict[str, Any]],
        image_analysis: Dict[str, Any],
        post_style: str,
        user_query: str = ""
    ) -> str:
        """
        Generate post content using LLM.
        
        Args:
            extracted_text: Text extracted from the image
            text_blocks: Structured text blocks from OCR
            image_analysis: Image analysis data
            post_style: Determined post style
            
        Returns:
            Generated post content
        """
        try:
            # Prepare the prompt
            prompt = self._create_prompt(extracted_text, text_blocks, image_analysis, post_style, user_query)
            
            role_prompt = """# è§’è‰²è®¾å®š  
ä½ æ˜¯ä¸€åå°çº¢ä¹¦çˆ†æ¬¾å†…å®¹åˆ›ä½œä¸“å®¶ï¼Œæ“…é•¿å°†æ™®é€šè¯é¢˜è½¬åŒ–ä¸ºå…·æœ‰ç—…æ¯’å¼ä¼ æ’­åŠ›çš„å®Œæ•´æ–‡ç« ã€‚ä½ çš„æ ¸å¿ƒèƒ½åŠ›åŒ…æ‹¬ï¼š  
1. æƒ…ç»ªé’©å­è®¾è®¡ï¼šè¿ç”¨â€œå¤¸å¼ æƒ…ç»ªè¯+åå¸¸è¯†è§‚ç‚¹â€å¼•çˆ†å¥½å¥‡å¿ƒï¼ˆå¦‚â€œå¤ªå¯æ€•äº†â€â€œè°æ‡‚å•Šâ€â€œç»ç»å­â€ï¼‰  
2. äºŒæžç®¡ç»“æž„æ³•ï¼šé€šè¿‡â€œç—›ç‚¹åˆºæ¿€-è§£å†³æ–¹æ¡ˆ-é€†å¤©æ•ˆæžœâ€ä¸‰æ®µå¼æ¡†æž¶åˆ¶é€ çˆ½æ„Ÿ  
3. å¹³å°åŒ–è¡¨è¾¾ï¼šå£è¯­åŒ–è¡Œæ–‡+é«˜é¢‘emoji+20å­—å†…çŸ­æ®µè½é€‚é…ç§»åŠ¨ç«¯é˜…è¯»  

# çˆ†æ¬¾æ–‡ç« ç”Ÿæˆå…¬å¼  
â–¶ æ ‡é¢˜å…¬å¼ï¼ˆä¿ç•™åŽŸè§„åˆ™å‡çº§ç‰ˆï¼‰  
`[æƒ…ç»ªè¯] + [åå¸¸è¯†ç»“æžœ] + [äººç¾¤æ ‡ç­¾] + [emoji]`  
âœ… ç¤ºä¾‹ï¼š  
> â€œå¤ªå¯æ€•äº†ï¼ç”¨ChatGPTå†™æ–‡æ¡ˆæœˆå…¥5w+ï¼Œæ‰“å·¥äººé€†è¢­æŒ‡å—ðŸ’¥â€  

â–¶ æ­£æ–‡ç»“æž„å…¬å¼  
1. æ®µè½å°æ ‡é¢˜ï¼ˆç®€æ´æ˜Žäº†ï¼‰
2. æƒ…ç»ªå†²å‡»å¼€å¤´ï¼ˆå¼•å‘å…±é¸£ï¼‰  
   - ç—›ç‚¹åœºæ™¯æ•…äº‹ï¼ˆ50å­—å†…ï¼‰+ å¤¸å¼ æƒ…ç»ªè¯  
   > *ä¾‹ï¼šâ€œè°æ‡‚å•Šï¼ç†¬å¤œå†™çš„æ–‡æ¡ˆ0ç‚¹èµžï¼ŒåŒäº‹ç”¨AI 3ç§’æ”¶å‰²10wæµé‡ï¼ï¼â€*
3. é¢ è¦†è®¤çŸ¥è½¬æŠ˜ï¼ˆåˆ¶é€ åå·®ï¼‰  
   - â€œç›´åˆ°æˆ‘å‘çŽ°...â€ + åå¸¸è¯†æ–¹æ³•ï¼ˆçªå‡ºç®€å•/é€Ÿæˆï¼‰  
4. å¹²è´§æ­¥éª¤æ‹†è§£ï¼ˆå®žç”¨ä»·å€¼ï¼‰  
   - åˆ†æ­¥éª¤+emojiå›¾æ ‡ + å…·ä½“æ¡ˆä¾‹ï¼ˆå¦‚â€œå®žæµ‹7å¤©æ¶¨ç²‰5åƒâ€ï¼‰  
5. é«˜æ½®é‡‘å¥ç‚¹é¢˜ï¼ˆåˆºæ¿€ä¼ æ’­ï¼‰  
   - ç”¨â€œè®°ä½ï¼š...â€å¥å¼+äº‰è®®æ€§è§‚ç‚¹ï¼ˆä¾‹ï¼šâ€œä¸ä¼šç”¨AIçš„æ–‡æ¡ˆäººï¼Œç»ˆå°†è¢«æ·˜æ±°ï¼â€ï¼‰  
6. äº’åŠ¨é’©å­ç»“å°¾ï¼ˆå¼•å¯¼è¡ŒåŠ¨ï¼‰  
   - â€œè¯„è®ºåŒºæ‰£ã€666ã€‘é¢†æŒ‡ä»¤åº“â€ / â€œæˆ³åˆé›†çœ‹100ä¸ªå˜çŽ°æ¡ˆä¾‹â€  

# åˆ›ä½œè§„åˆ™  
1. å†…å®¹é•¿åº¦ï¼šæ­£æ–‡300-500å­—ï¼Œåˆ†3-5æ®µï¼Œå¹¶é…ä¸Šæ®µè½å°æ ‡é¢˜ï¼Œæ¯æ®µâ‰¤3è¡Œ  
2. å…³é”®è¯æ¤å…¥ï¼šä»Žç”¨æˆ·æä¾›çš„å…³é”®è¯åº“é€‰3ä¸ªè‡ªç„¶èžå…¥ï¼ˆå¦‚â€œåè¡€æ•´ç†â€â€œæ‰‹æ®‹å…šå¿…å¤‡â€ï¼‰  
3. å¹³å°ç‰¹æ€§ï¼š  
   - æ¯æ®µå°½é‡æœ‰æ®µè½å°æ ‡é¢˜ï¼Œå¹¶åœ¨æ®µè½æ ‡é¢˜å’Œæ­£æ–‡ä¸­æ’å…¥1-2ä¸ªðŸ”¥â­ðŸ’¡ç±»é«˜äº®emoji
   - å…³é”®ä¿¡æ¯ç”¨â€œï¼â€æ ‡ç‚¹å¼ºåŒ–æƒ…ç»ª
4. ç¦å¿Œï¼š
   Ã— é¿å…é•¿æ®µè½ï¼ˆæ¯æ®µâ‰¤3è¡Œï¼‰  
   Ã— ç¦æ­¢ç›´æŽ¥å‡ºçŽ°"å°çº¢ä¹¦"ã€"ç²‰ä¸"ç­‰å¹³å°è¯  
   Ã— ç¦ç”¨å¤æ‚æ ‡ç­¾ï¼ˆåŽç»­å•ç‹¬å¤„ç†ï¼‰ 
            """

            response = self._call_llm(prompt, system_prompt=role_prompt, max_tokens=8192)
            # print(response)

            return response
            
        except Exception as e:
            # Fallback content in case of API error
            print(f"Error generating content: {e}")
            return self._generate_fallback_content(extracted_text, post_style)
    
    def _create_prompt(
        self, 
        extracted_text: str, 
        text_blocks: List[Dict[str, Any]],
        image_analysis: Dict[str, Any],
        post_style: str,
        user_query: str = ""
    ) -> str:
        """
        Create a prompt for the LLM to generate post content.
        
        Args:
            extracted_text: Text extracted from the image
            text_blocks: Structured text blocks from OCR
            image_analysis: Image analysis data
            post_style: Determined post style
            
        Returns:
            Prompt string
        """
        # Extract relevant image information
        dimensions = image_analysis.get("dimensions", {})
        color_info = image_analysis.get("color_info", {})

        # Image details:
        # - Dimensions: {dimensions.get('width', 'unknown')}x{dimensions.get('height', 'unknown')}
        # - Brightness: {'Bright' if color_info.get('is_bright', False) else 'Dark'}
        
        
        prompt = f"""è¯·ä½ æ ¹æ®ä»¥ä¸‹æ–‡æœ¬å†…å®¹ã€é£Žæ ¼ã€å’Œç”¨æˆ·å¯¹è¯å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªå°çº¢ä¹¦çˆ†æ¬¾æ–‡ç« é£Žæ ¼çš„æŽ¨æ–‡ï¼š

æ–‡æœ¬å†…å®¹ï¼š{extracted_text}

é£Žæ ¼ï¼š{post_style}

ç”¨æˆ·å¯¹è¯å†…å®¹ï¼š{user_query}

è¯·æ³¨æ„ï¼šå–„ç”¨æƒ…ç»ªé’©å­ã€å¹³å°åŒ–è¡¨è¾¾ã€‚å¤šåˆ†æ®µè½ï¼Œå¹¶æ·»åŠ emojiã€‚è¯·ä½ ç›´æŽ¥è¿”å›žä½ ç”Ÿæˆçš„æŽ¨æ–‡ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹ã€‚
        """
        
        return prompt
    
    def _generate_fallback_content(self, extracted_text: str, post_style: str) -> str:
        """
        Generate fallback content when API call fails.
        
        Args:
            extracted_text: Text extracted from the image
            post_style: Determined post style
            
        Returns:
            Fallback content
        """
        # Extract a few words from the text to personalize the fallback
        words = extracted_text.split()
        sample_text = " ".join(words[:10]) if len(words) > 10 else extracted_text
        
        templates = [
            f"ä»Šå¤©å‘çŽ°äº†ä¸€ä¸ªè¶…æ£’çš„{post_style}å¥½ç‰©ï¼{sample_text}... çœŸçš„å¾ˆæŽ¨èå¤§å®¶å°è¯•ä¸€ä¸‹ï½ž",
            f"åˆ†äº«ä¸€ä¸‹æˆ‘æœ€è¿‘è¶…çˆ±çš„{post_style}å¿ƒå¾—ï¼{sample_text}... å¸Œæœ›å¯¹ä½ ä¹Ÿæœ‰å¸®åŠ©ï½ž",
            f"å¶ç„¶é—´å‘çŽ°çš„{post_style}å®è—ï¼{sample_text}... çœŸçš„æ˜¯ç›¸è§æ¨æ™šï¼"
        ]
        
        return random.choice(templates)
    
    def _get_emojis(self, post_style: str, count: int = 5) -> List[str]:
        """
        Get relevant emojis for the post.
        
        Args:
            post_style: Post style category
            count: Maximum number of emojis to include
            
        Returns:
            List of emoji strings
        """
        style_emojis = self.emoji_sets.get(post_style, ["âœ¨", "ðŸ’«", "ðŸŒˆ", "ðŸ’–", "ðŸ¥°", "ðŸŒŸ", "ðŸŒ±"])
        
        # Select random emojis from the style category
        if style_emojis:
            # Ensure we don't try to select more emojis than available
            available_count = min(count, len(style_emojis))
            selected_emojis = random.sample(style_emojis, available_count)
        else:
            selected_emojis = ["âœ¨", "ðŸ’«"]
        
        return selected_emojis
    
    def _format_post(self, content: str, hashtags: List[str], emojis: List[str]) -> str:
        """
        Format the final post with content, hashtags, and emojis.
        
        Args:
            content: Generated post content
            hashtags: Selected hashtags
            emojis: Selected emojis
            
        Returns:
            Formatted post string
        """
        # Add random emojis throughout the content
        paragraphs = content.split("\n\n")
        formatted_paragraphs = []
        
        for i, paragraph in enumerate(paragraphs):
            if paragraph.strip():
                # Add an emoji at the beginning or end of some paragraphs
                if random.random() > 0.5 and emojis:
                    emoji = random.choice(emojis)
                    if random.random() > 0.5:
                        paragraph = f"{emoji} {paragraph}"
                    else:
                        paragraph = f"{paragraph} {emoji}"
                formatted_paragraphs.append(paragraph)
        
        # Join paragraphs
        formatted_content = "\n\n".join(formatted_paragraphs)
        
        # Add hashtags at the end
        hashtag_section = " ".join(hashtags)
        
        # Final post
        final_post = f"{formatted_content}\n\n{hashtag_section}"
        
        return final_post


# Example usage
if __name__ == "__main__":
    generator = PostGenerator()
    
    # Sample image data
    sample_data = {
        "text": "ä»Šå¤©åŽ»äº†æ–°å¼€çš„å’–å•¡åº—ï¼ŒçŽ¯å¢ƒè¶…çº§å¥½ï¼Œå’–å•¡ä¹Ÿå¾ˆé¦™æµ“",
        "text_blocks": [],
        "language": "zh",
        "analysis": {
            "dimensions": {"width": 1080, "height": 1920, "aspect_ratio": 0.5625},
            "color_info": {"is_bright": True, "dominant_colors": [[240, 240, 240], [200, 180, 160]]}
        }
    }
    
    post = generator.generate_post(sample_data)
    print(json.dumps(post, ensure_ascii=False, indent=2))
